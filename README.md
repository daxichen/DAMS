# DAMS
# Decoupling and Aligning Modality-Shared Semantics for Single-Domain Generalization in Hyperspectral Image Classification （Under Review）
![DAMS Framework](figure/DAMS.png)
DAMS processes spectral patches from HSIs, which undergo both weak and strong data augmentation, alongside their corresponding class-universal language descriptions. A weight-sharing hyperspectral encoder extracts visual features from these patches, while a text encoder generates textual features from the language descriptions. The core methodology involves several key stages: **(1)** decoupling the extracted visual and textual features into distinct modality-shared semantic components and modality-specific attributes; **(2)** aligning the modality-shared semantic components from both visual and textual sources within a common embedding space using modality-shared supervised contrastive learning, while simultaneously ensuring modality-specific attributes remain distinct from these shared semantics; **(3)** employing a cross-modal transformation module for bidirectional feature mapping (visual-to-textual and textual-to-visual); this module uses a reconstruction loss to enforce semantic consistency between original and transformed features across modalities; and **(4)** applying an InfoNCE loss to textual representations that are generated by the visual-to-text transformation of features from weakly and strongly augmented versions of the same spectral patch. This InfoNCE loss acts as a self-supervisory signal, compelling the hyperspectral encoder to learn representations that are robust to input variations and preserve core class-specific semantics, thereby enhancing generalization. Notably, during the testing phase, only the hyperspectral encoder and a classifier are utilized for cross-scene HSIC.

# Requirements：
```
1. torch==1.11.0+cu113
2. python==3.8.3
```
# Dataset:
The dataset can be downloaded from here: [HSI datasets](https://github.com/YuxiangZhang-BIT/Data-CSHSI). We greatly appreciate their outstanding contributions.

The dataset directory should look like this:
```
datasets
  Houston
  ├── Houston13.mat
  ├── Houston13_7gt.mat
  ├── Houston18.mat
  └── Houston18_7gt.mat
```

# Usage:
Houston datasets:
```
python inference.py --save_path ./results/ --data_path ./datasets/Houston/ --target_name Houston18 --patch_size 13 --layers 2
```
